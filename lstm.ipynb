{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "RANDOM_SEED = 577\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gensim.downloader as api\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "glove_vectors = api.load(\"glove-twitter-25\")\n",
    "\n",
    "def tokenize(text, max_len=25):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) < max_len:\n",
    "        tokens += ['<pad>'] * (max_len - len(tokens))\n",
    "    return tokens[:max_len]\n",
    "\n",
    "def preprocess_data(data, glove_vectors, label_encoder):\n",
    "    texts = data['text'].apply(tokenize).tolist()\n",
    "    texts = [[glove_vectors[token] if token in glove_vectors else np.zeros(25) for token in text] for text in texts]\n",
    "    labels = label_encoder.fit_transform(data['emoji_id'])\n",
    "    return np.array(texts), labels, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_data = pd.read_csv(\"dataset/train_data.csv\").dropna()\n",
    "# train_data = pd.read_csv(\"dataset/train_data_augmented.csv\").dropna()\n",
    "validate_data = pd.read_csv(\"dataset/validate_data.csv\").dropna()\n",
    "test_data = pd.read_csv(\"dataset/test_data.csv\").dropna()\n",
    "\n",
    "train_texts, train_labels, label_encoder = preprocess_data(train_data, glove_vectors, label_encoder)\n",
    "test_texts, test_labels, _ = preprocess_data(test_data, glove_vectors, label_encoder)\n",
    "validate_texts, validate_labels, _ = preprocess_data(validate_data, glove_vectors, label_encoder)\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels)\n",
    "test_dataset = TextDataset(test_texts, test_labels)\n",
    "validate_dataset = TextDataset(validate_texts, validate_labels)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden.squeeze(0))\n",
    "        return out\n",
    "    \n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        hidden = torch.cat((hidden[0, :, :], hidden[1, :, :]), dim=1)\n",
    "        out = self.fc(hidden)\n",
    "        return out\n",
    "\n",
    "input_dim = 25\n",
    "hidden_dim = 64\n",
    "output_dim = 100\n",
    "model = LSTMClassifier(input_dim, hidden_dim, output_dim)\n",
    "# model = BiLSTMClassifier(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "\n",
    "    for texts, labels in dataloader:\n",
    "        texts = texts.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in dataloader:\n",
    "            texts = texts.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40:\n",
      "Train Loss: 3.9201\n",
      "Test Loss: 3.7651, Validate Accuracy: 0.1235 Test Accuracy: 0.1250\n",
      "Epoch 2/40:\n",
      "Train Loss: 3.7370\n",
      "Test Loss: 3.6615, Validate Accuracy: 0.1524 Test Accuracy: 0.1582\n",
      "Epoch 3/40:\n",
      "Train Loss: 3.6032\n",
      "Test Loss: 3.5177, Validate Accuracy: 0.1698 Test Accuracy: 0.1677\n",
      "Epoch 4/40:\n",
      "Train Loss: 3.4843\n",
      "Test Loss: 3.4082, Validate Accuracy: 0.1784 Test Accuracy: 0.1838\n",
      "Epoch 5/40:\n",
      "Train Loss: 3.4003\n",
      "Test Loss: 3.3165, Validate Accuracy: 0.2024 Test Accuracy: 0.2049\n",
      "Epoch 6/40:\n",
      "Train Loss: 3.3089\n",
      "Test Loss: 3.2555, Validate Accuracy: 0.2014 Test Accuracy: 0.2095\n",
      "Epoch 7/40:\n",
      "Train Loss: 3.2488\n",
      "Test Loss: 3.2099, Validate Accuracy: 0.2070 Test Accuracy: 0.2144\n",
      "Epoch 8/40:\n",
      "Train Loss: 3.1964\n",
      "Test Loss: 3.1627, Validate Accuracy: 0.2089 Test Accuracy: 0.2256\n",
      "Epoch 9/40:\n",
      "Train Loss: 3.1352\n",
      "Test Loss: 3.0969, Validate Accuracy: 0.2224 Test Accuracy: 0.2378\n",
      "Epoch 10/40:\n",
      "Train Loss: 3.0692\n",
      "Test Loss: 3.0528, Validate Accuracy: 0.2260 Test Accuracy: 0.2486\n",
      "Epoch 11/40:\n",
      "Train Loss: 3.0247\n",
      "Test Loss: 2.9980, Validate Accuracy: 0.2428 Test Accuracy: 0.2585\n",
      "Epoch 12/40:\n",
      "Train Loss: 2.9729\n",
      "Test Loss: 2.9720, Validate Accuracy: 0.2434 Test Accuracy: 0.2595\n",
      "Epoch 13/40:\n",
      "Train Loss: 2.9291\n",
      "Test Loss: 2.9482, Validate Accuracy: 0.2503 Test Accuracy: 0.2700\n",
      "Epoch 14/40:\n",
      "Train Loss: 2.8957\n",
      "Test Loss: 2.9029, Validate Accuracy: 0.2628 Test Accuracy: 0.2726\n",
      "Epoch 15/40:\n",
      "Train Loss: 2.8590\n",
      "Test Loss: 2.8866, Validate Accuracy: 0.2622 Test Accuracy: 0.2782\n",
      "Epoch 16/40:\n",
      "Train Loss: 2.8308\n",
      "Test Loss: 2.8712, Validate Accuracy: 0.2700 Test Accuracy: 0.2858\n",
      "Epoch 17/40:\n",
      "Train Loss: 2.8033\n",
      "Test Loss: 2.8548, Validate Accuracy: 0.2714 Test Accuracy: 0.2825\n",
      "Epoch 18/40:\n",
      "Train Loss: 2.7773\n",
      "Test Loss: 2.8220, Validate Accuracy: 0.2730 Test Accuracy: 0.2904\n",
      "Epoch 19/40:\n",
      "Train Loss: 2.7479\n",
      "Test Loss: 2.8129, Validate Accuracy: 0.2723 Test Accuracy: 0.2940\n",
      "Epoch 20/40:\n",
      "Train Loss: 2.7233\n",
      "Test Loss: 2.8126, Validate Accuracy: 0.2750 Test Accuracy: 0.2933\n",
      "Epoch 21/40:\n",
      "Train Loss: 2.7013\n",
      "Test Loss: 2.7859, Validate Accuracy: 0.2769 Test Accuracy: 0.2930\n",
      "Epoch 22/40:\n",
      "Train Loss: 2.6853\n",
      "Test Loss: 2.7682, Validate Accuracy: 0.2871 Test Accuracy: 0.2979\n",
      "Epoch 23/40:\n",
      "Train Loss: 2.6617\n",
      "Test Loss: 2.7741, Validate Accuracy: 0.2894 Test Accuracy: 0.2956\n",
      "Epoch 24/40:\n",
      "Train Loss: 2.6435\n",
      "Test Loss: 2.7896, Validate Accuracy: 0.2812 Test Accuracy: 0.2897\n",
      "Epoch 25/40:\n",
      "Train Loss: 2.6242\n",
      "Test Loss: 2.7553, Validate Accuracy: 0.2930 Test Accuracy: 0.2983\n",
      "Epoch 26/40:\n",
      "Train Loss: 2.6063\n",
      "Test Loss: 2.7613, Validate Accuracy: 0.2957 Test Accuracy: 0.2956\n",
      "Epoch 27/40:\n",
      "Train Loss: 2.5921\n",
      "Test Loss: 2.7430, Validate Accuracy: 0.2970 Test Accuracy: 0.2986\n",
      "Epoch 28/40:\n",
      "Train Loss: 2.5760\n",
      "Test Loss: 2.7613, Validate Accuracy: 0.2927 Test Accuracy: 0.2992\n",
      "Epoch 29/40:\n",
      "Train Loss: 2.5571\n",
      "Test Loss: 2.7584, Validate Accuracy: 0.2852 Test Accuracy: 0.2969\n",
      "Epoch 30/40:\n",
      "Train Loss: 2.5383\n",
      "Test Loss: 2.7559, Validate Accuracy: 0.2943 Test Accuracy: 0.2992\n",
      "Epoch 31/40:\n",
      "Train Loss: 2.5233\n",
      "Test Loss: 2.7361, Validate Accuracy: 0.2927 Test Accuracy: 0.3006\n",
      "Epoch 32/40:\n",
      "Train Loss: 2.5108\n",
      "Test Loss: 2.7485, Validate Accuracy: 0.2914 Test Accuracy: 0.3022\n",
      "Epoch 33/40:\n",
      "Train Loss: 2.4959\n",
      "Test Loss: 2.7360, Validate Accuracy: 0.2881 Test Accuracy: 0.3045\n",
      "Epoch 34/40:\n",
      "Train Loss: 2.4799\n",
      "Test Loss: 2.7393, Validate Accuracy: 0.2960 Test Accuracy: 0.3058\n",
      "Epoch 35/40:\n",
      "Train Loss: 2.4661\n",
      "Test Loss: 2.7326, Validate Accuracy: 0.2970 Test Accuracy: 0.3029\n",
      "Epoch 36/40:\n",
      "Train Loss: 2.4508\n",
      "Test Loss: 2.7629, Validate Accuracy: 0.2875 Test Accuracy: 0.2976\n",
      "Epoch 37/40:\n",
      "Train Loss: 2.4393\n",
      "Test Loss: 2.7611, Validate Accuracy: 0.2898 Test Accuracy: 0.2979\n",
      "Epoch 38/40:\n",
      "Train Loss: 2.4260\n",
      "Test Loss: 2.7440, Validate Accuracy: 0.2920 Test Accuracy: 0.3078\n",
      "Epoch 39/40:\n",
      "Train Loss: 2.4145\n",
      "Test Loss: 2.7651, Validate Accuracy: 0.2914 Test Accuracy: 0.3055\n",
      "Epoch 40/40:\n",
      "Train Loss: 2.4072\n",
      "Test Loss: 2.7459, Validate Accuracy: 0.2901 Test Accuracy: 0.3035\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "    validate_loss, validate_accuracy = evaluate(model, validate_dataloader, criterion, device)\n",
    "    test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Validate Accuracy: {validate_accuracy:.4f} Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1345540889515316\n",
      "F1 Score Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.09      0.10        22\n",
      "           1       0.36      0.64      0.46       380\n",
      "           2       0.25      0.06      0.09        35\n",
      "           3       0.21      0.28      0.24        32\n",
      "           4       0.35      0.27      0.31        22\n",
      "           5       0.38      0.47      0.42        43\n",
      "           6       0.17      0.20      0.18         5\n",
      "           7       0.27      0.34      0.30       182\n",
      "           8       0.47      0.19      0.27        37\n",
      "           9       0.29      0.41      0.34        75\n",
      "          10       0.53      0.54      0.53        82\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.23      0.20      0.21        82\n",
      "          13       0.20      0.18      0.19        11\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.41      0.39      0.40       117\n",
      "          16       0.30      0.61      0.40        79\n",
      "          17       0.23      0.48      0.31        46\n",
      "          18       0.00      0.00      0.00        22\n",
      "          19       0.17      0.09      0.12        22\n",
      "          20       0.15      0.25      0.19        12\n",
      "          21       0.37      0.33      0.35        88\n",
      "          22       1.00      0.04      0.07        28\n",
      "          23       0.31      0.33      0.32       247\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.20      0.25      0.23       108\n",
      "          26       0.40      0.40      0.40        42\n",
      "          27       0.00      0.00      0.00        23\n",
      "          28       0.00      0.00      0.00        11\n",
      "          29       0.12      0.07      0.09        30\n",
      "          30       0.05      0.17      0.08         6\n",
      "          31       0.30      0.37      0.34       214\n",
      "          32       0.17      0.11      0.13         9\n",
      "          33       0.29      0.50      0.37        40\n",
      "          34       0.21      0.11      0.14        28\n",
      "          35       0.17      0.17      0.17       138\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.30      0.19      0.23        16\n",
      "          38       0.57      0.57      0.57        28\n",
      "          39       0.33      0.20      0.25         5\n",
      "          40       0.33      0.67      0.44         3\n",
      "          41       0.00      0.00      0.00        21\n",
      "          42       0.40      0.10      0.15        21\n",
      "          43       0.33      0.15      0.21        13\n",
      "          44       0.00      0.00      0.00        15\n",
      "          45       0.19      0.18      0.19        38\n",
      "          46       0.00      0.00      0.00        10\n",
      "          47       0.40      0.12      0.19        16\n",
      "          48       0.00      0.00      0.00        11\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.00      0.00      0.00        20\n",
      "          51       0.20      0.21      0.20        42\n",
      "          52       0.00      0.00      0.00         3\n",
      "          53       0.07      0.02      0.03        66\n",
      "          54       0.00      0.00      0.00         3\n",
      "          55       0.00      0.00      0.00        31\n",
      "          56       0.00      0.00      0.00         7\n",
      "          57       0.00      0.00      0.00         5\n",
      "          58       0.33      0.20      0.25         5\n",
      "          59       0.50      0.20      0.29         5\n",
      "          60       0.22      0.31      0.26        13\n",
      "          61       0.00      0.00      0.00         8\n",
      "          62       0.20      0.14      0.17         7\n",
      "          63       0.20      0.06      0.09        18\n",
      "          64       0.00      0.00      0.00        17\n",
      "          65       0.30      0.12      0.17        25\n",
      "          66       0.00      0.00      0.00         5\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       1.00      0.25      0.40         4\n",
      "          69       0.00      0.00      0.00         9\n",
      "          70       0.00      0.00      0.00         5\n",
      "          71       0.00      0.00      0.00         4\n",
      "          72       0.00      0.00      0.00        11\n",
      "          73       0.47      0.73      0.57        11\n",
      "          74       0.00      0.00      0.00         6\n",
      "          75       0.00      0.00      0.00         7\n",
      "          76       0.00      0.00      0.00        10\n",
      "          77       0.00      0.00      0.00         7\n",
      "          78       0.00      0.00      0.00        10\n",
      "          79       1.00      0.20      0.33         5\n",
      "          80       0.00      0.00      0.00        11\n",
      "          81       0.00      0.00      0.00         8\n",
      "          82       0.00      0.00      0.00         7\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.33      0.43      0.38         7\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         8\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.00      0.00      0.00         4\n",
      "          91       0.00      0.00      0.00         4\n",
      "          92       0.00      0.00      0.00         9\n",
      "          93       0.00      0.00      0.00        10\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       1.00      0.20      0.33         5\n",
      "          96       0.00      0.00      0.00         8\n",
      "          97       0.00      0.00      0.00         9\n",
      "          98       0.00      0.00      0.00         3\n",
      "          99       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.30      3041\n",
      "   macro avg       0.17      0.14      0.13      3041\n",
      "weighted avg       0.27      0.30      0.27      3041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server0/a/wu1522/miniconda3/envs/cuda11.6-python3-pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/server0/a/wu1522/miniconda3/envs/cuda11.6-python3-pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/server0/a/wu1522/miniconda3/envs/cuda11.6-python3-pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "total_loss = 0\n",
    "correct_predictions = 0\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_dataloader:\n",
    "        texts = texts.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "f1_score_report = classification_report(true_labels, predicted_labels)\n",
    "print(f1_score(true_labels, predicted_labels, average=\"macro\"))\n",
    "print(\"F1 Score Report:\")\n",
    "print(f1_score_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3881,  0.7737, -2.6321, -0.6916,  1.8788, -0.6636, -4.2960,  2.1215,\n",
      "         1.8819, -1.4105,  3.3556, -3.8281,  2.1295, -2.4174, -0.4658,  1.7660,\n",
      "         0.4057,  0.4085, -2.2496,  1.5592, -3.1648,  1.8142,  1.5714,  1.6155,\n",
      "        -5.0158,  3.1899,  4.3539,  3.1509,  1.1585, -1.4840, -2.4338,  3.0269,\n",
      "        -2.9716,  0.5610, -3.6026,  1.4237, -1.6494, -0.4749,  3.6958, -0.4219,\n",
      "        -6.3038,  0.4216,  1.2911, -1.9801, -2.8276,  1.6085, -1.4649,  4.5820,\n",
      "        -5.3860,  0.7679,  1.4205,  1.7213, -2.6229,  1.9492, -3.1688,  2.2182,\n",
      "        -4.6649, -3.4121, -3.6325,  6.3724, -0.3269, -0.9522, -1.6883, -0.7527,\n",
      "        -2.8364,  1.3061,  2.4469,  2.6759, -1.3992, -0.5384, -1.3752, -4.1693,\n",
      "        -0.9802, -3.7932,  1.0751, -1.2906, -3.1309,  4.3691, -5.7382,  0.9096,\n",
      "         0.0356, -0.6946, -2.3927,  0.4154, -1.5777, -3.4246, -0.7763, -3.1403,\n",
      "        -4.2069, -0.9246, -2.3919,  0.9757, -1.3427,  0.7693, -4.5236, -3.0440,\n",
      "        -2.7286, -1.3618, -3.4593, -2.3949], device='cuda:0')\n",
      "The predicted label for the tweet is: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_215622/3843340456.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tweet_tensor = torch.tensor([tweet_embedding], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "def predict(tweet, model, glove_vectors, label_encoder):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tokenized_tweet = tokenize(tweet)\n",
    "    tweet_embedding = [glove_vectors[token] if token in glove_vectors else np.zeros(25) for token in tokenized_tweet]\n",
    "    tweet_tensor = torch.tensor([tweet_embedding], dtype=torch.float)\n",
    "    tweet_tensor = tweet_tensor.to(device, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        output = model(tweet_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(sum(output))\n",
    "        label = label_encoder.inverse_transform(predicted.cpu().numpy())[0]\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Example usage:\n",
    "tweet = \"good night\"\n",
    "predicted_label = predict(tweet, model, glove_vectors, label_encoder)\n",
    "print(f\"The predicted label for the tweet is: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_map = {}\n",
    "for i, j in zip(train_data[\"emoji\"], train_data[\"emoji_id\"]):\n",
    "  if i not in emoji_map:\n",
    "    emoji_map[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸŒ™'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_emoji_map = {value: key for key, value in emoji_map.items()}\n",
    "reversed_emoji_map[predicted_label][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# def flatten_embeddings(texts):\n",
    "#     return np.array([np.array(text).flatten() for text in texts])\n",
    "\n",
    "# flat_train_texts = flatten_embeddings(train_texts)\n",
    "# flat_test_texts = flatten_embeddings(test_texts)\n",
    "\n",
    "# svm_model = SVC(kernel='linear')\n",
    "# svm_model.fit(flat_train_texts, train_labels)\n",
    "\n",
    "# train_predictions = svm_model.predict(flat_train_texts)\n",
    "# test_predictions = svm_model.predict(flat_test_texts)\n",
    "\n",
    "# train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "# test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11.6-python3-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
